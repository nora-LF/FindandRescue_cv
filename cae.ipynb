{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17f9f0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_data\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a41005a34d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    268\u001b[0m                     \u001b[0;31m# Cannot statically verify that dataset is Sized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                     \u001b[0;31m# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0m\u001b[1;32m    103\u001b[0m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Dataset5(Dataset):\n",
    "    def __init__(self, root):\n",
    "        \"\"\"\n",
    "        :param root: image folder\n",
    "        \"\"\"\n",
    "        img_paths = glob.glob(os.path.join(root, '**/*.png'), recursive=True)\n",
    "        img_paths.sort(key=str)\n",
    "        data_array = np.empty(shape=(len(img_paths), 256, 256, 3), dtype=np.float32)\n",
    "        for i, n in enumerate(img_paths):\n",
    "            img = cv2.imread(n, cv2.IMREAD_REDUCED_COLOR_4)\n",
    "            data_array[i, ...] = img\n",
    "        self.data = np.moveaxis(data_array, -1, 1)\n",
    "        self.root = root\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = self.data[item, ...]\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "### Autoencoder\n",
    "\n",
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self, in_channels: int, hid_channels: int, code_channels: int,\n",
    "                 kernel_size: int, stride: int = 1, pooling: int = 2,\n",
    "                 activation: nn.Module = nn.ReLU()):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_hidden = nn.Conv2d(in_channels=in_channels,\n",
    "                                        out_channels=hid_channels,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        stride=stride)\n",
    "        self.encoder_pool = nn.AvgPool2d(kernel_size=pooling)\n",
    "        self.encoder_output = nn.Conv2d(in_channels=hid_channels,\n",
    "                                        out_channels=code_channels,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        stride=stride)\n",
    "\n",
    "        self.act = activation\n",
    "\n",
    "        self.decoder_hidden = nn.ConvTranspose2d(in_channels=code_channels,\n",
    "                                                 out_channels=hid_channels,\n",
    "                                                 kernel_size=kernel_size,\n",
    "                                                 stride=stride)\n",
    "        self.decoder_unpool = nn.ConvTranspose2d(in_channels=hid_channels,\n",
    "                                                 out_channels=hid_channels,\n",
    "                                                 kernel_size=pooling,\n",
    "                                                 stride=pooling)\n",
    "\n",
    "        self.decoder_unpool.weight.data.fill_(1 / (pooling * pooling))\n",
    "        self.decoder_unpool.weight.requires_grad = False\n",
    "        self.decoder_unpool.bias.requires_grad = False\n",
    "\n",
    "        self.decoder_output = nn.ConvTranspose2d(in_channels=hid_channels,\n",
    "                                                 out_channels=in_channels,\n",
    "                                                 kernel_size=kernel_size,\n",
    "                                                 stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder_hidden(x)\n",
    "        x = self.act(x)\n",
    "        x = self.encoder_pool(x)\n",
    "        x = self.encoder_output(x)\n",
    "        x = self.act(x)\n",
    "        x = self.decoder_hidden(x)\n",
    "        x = self.decoder_unpool(x)\n",
    "        x = self.act(x)\n",
    "        x = self.decoder_output(x)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def reconstruct(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x : torch.Tensor\n",
    "            Inputs to be reconstructed.\n",
    "        y : torch.Tensor\n",
    "            Result of reconstruction, with values\n",
    "            in the same range as the targets.\n",
    "        \"\"\"\n",
    "        logits = self.forward(x)\n",
    "        return torch.clamp(logits, x.min(), x.max())\n",
    "\n",
    "\n",
    "def _forward(network: nn.Module, data: DataLoader, metric: callable):\n",
    "    device = next(network.parameters()).device\n",
    "\n",
    "    for x in data:\n",
    "        x, y = x.to(device), x.to(device)\n",
    "        logits = network(x)\n",
    "        res = metric(logits, y)\n",
    "        yield res\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(network: nn.Module, data: DataLoader, metric: callable) -> list:\n",
    "    network.eval()\n",
    "\n",
    "    results = _forward(network, data, metric)\n",
    "    return [res.item() for res in results]\n",
    "\n",
    "\n",
    "@torch.enable_grad()\n",
    "def update(network: nn.Module, data: DataLoader, loss: nn.Module,\n",
    "           opt: optim.Optimizer) -> list:\n",
    "    network.train()\n",
    "\n",
    "    errs = []\n",
    "    for err in _forward(network, data, loss):\n",
    "        errs.append(err.item())\n",
    "\n",
    "        opt.zero_grad()\n",
    "        err.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return errs\n",
    "\n",
    "\n",
    "def train_auto_encoder(auto_encoder: nn.Module, loader: DataLoader,\n",
    "                       objective: nn.Module, optimiser: optim.Optimizer,\n",
    "                       num_epochs: int = 10, vis_every: int = 5):\n",
    "\n",
    "    # take random batch for visualising reconstructions\n",
    "    #ref_inputs, _ = next(iter(loader))\n",
    "    ref_inputs = next(iter(loader))\n",
    "\n",
    "    # evaluate random performance\n",
    "    errs = evaluate(auto_encoder, loader, objective)\n",
    "    print(f\"Epoch {0: 2d} - avg loss: {sum(errs) / len(errs):.6f}\")\n",
    "    #display_result(auto_encoder, ref_inputs)\n",
    "\n",
    "    # train for some epochs\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        errs = update(auto_encoder, loader, objective, optimiser)\n",
    "        print(f\"Epoch {epoch: 2d} - avg loss: {sum(errs) / len(errs):.6f}\")\n",
    "\n",
    "        #if epoch % vis_every == 0:\n",
    "            #display_result(auto_encoder, ref_inputs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root_dir = r\"preprocessed_data\"\n",
    "dataset = Dataset5(root=root_dir)\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 7\n",
    "lr = 1e-4\n",
    "\n",
    "#examples_to_show = 8\n",
    "\n",
    "### parameters for autoencoder\n",
    "in_channels = 3\n",
    "hid_channels = 128\n",
    "code_channels = 8\n",
    "kernel_size = 5\n",
    "pooling = 2\n",
    "\n",
    "\n",
    "### Start of training\n",
    "\n",
    "print(dataset.root)\n",
    "print(len(dataset))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=7, shuffle=True, num_workers=0)\n",
    "\n",
    "print(next(iter(train_loader)).shape)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "model = ConvAutoEncoder(in_channels = in_channels, hid_channels = hid_channels, code_channels = code_channels, kernel_size = kernel_size, pooling = pooling)\n",
    "opt = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "print(\"Code size:\", int(code_channels*((28-kernel_size+1)/pooling-kernel_size+1)**2))\n",
    "\n",
    "train_auto_encoder(auto_encoder = model, loader = train_loader,\n",
    "                   objective = loss_func, optimiser = opt, num_epochs = epochs)\n",
    "\n",
    "torch.save(model, 'trained_model.pt')\n",
    "print(\"finished training\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c681b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
